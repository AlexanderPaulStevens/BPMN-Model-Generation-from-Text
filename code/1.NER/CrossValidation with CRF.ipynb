{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#1. Introduction\n","\n","This notebook will contain steps to train and predict with a CRF model using PyCRFSuite for the NER task as well as Crossvalidation for evaluation. The files you will need for this colab are \"PETv1.1-entities.jsonl\", \"complete_combined_leschneiderdata_NER.jsonl\" and \"glove.6B.300d.txt\". The GloVe pre-trained model can be downloaded from the link in \"Pre-Trained NER Models Links\"."],"metadata":{"id":"Wh9wxwSVjIWX"}},{"cell_type":"code","source":["#@title 1.1. Importing and Installing libraries\n","%%capture\n","import os\n","# Define the path to the flag file, we do this so you can rerun the whole colab on different examples without having to wait 4 minutes each time.\n","flag_file_installations = '/content/installed_flag'\n","\n","# Check if the flag file exists\n","if not os.path.exists(flag_file_installations):\n","\n","  !pip install python-crfsuite\n","  !python -m spacy download en_core_web_md\n","\n","  import json\n","  import pandas as pd\n","  import copy\n","  import numpy as np\n","  from itertools import product\n","  import spacy\n","  import json\n","  from itertools import product\n","  from sklearn.preprocessing import LabelEncoder\n","  from google.colab import drive\n","  import nltk\n","  from nltk import pos_tag\n","  from nltk.tokenize import word_tokenize\n","  import typing\n","  import pycrfsuite  # For CRF training\n","  from sklearn.model_selection import train_test_split\n","  from sklearn.metrics import f1_score, classification_report\n","  from sklearn.model_selection import KFold\n","  from sklearn.metrics import classification_report, precision_recall_fscore_support, f1_score\n","\n","  import random\n","  SEED = 42\n","\n","  nltk.download('averaged_perceptron_tagger')\n","  drive.mount('/content/drive')\n","  # Create the flag file\n","  with open(flag_file_installations, 'w') as f:\n","      f.write('Installed')\n","else:\n","    print(\"Packages already installed. Skipping installations.\")"],"metadata":{"collapsed":true,"id":"SixKWsYrjR_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Loading Data\n","def load_and_group_ner_data(file_path):\n","    grouped_data = {}\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            entry = json.loads(line)\n","            document_name = entry['document name']  # Adjusted to use 'document name'\n","            if document_name not in grouped_data:\n","                grouped_data[document_name] = []\n","            grouped_data[document_name].append(entry)\n","            #print(entry)\n","    # Sort each group by 'sentence-ID'\n","    for doc in grouped_data.values():\n","        doc.sort(key=lambda x: x['sentence-ID'])\n","\n","    return list(grouped_data.values())\n","try:\n","  PET_Folder = '/content/drive/MyDrive/THESIS/DATA/PET/actual PET data from Patrizio Bellan/PETv1.1-entities.jsonl'\n","  LESCHNEIDER_Folder = '/content/drive/MyDrive/THESIS/DATA/LESCHNEIDER DATA/Documents/FORMATTED_DATA_ELEMENTS/complete_combined_leschneiderdata_NER.jsonl'\n","\n","  # Load and group data from both files calling on a function above\n","  grouped_data_1 = load_and_group_ner_data(PET_Folder)\n","  grouped_data_2 = load_and_group_ner_data(LESCHNEIDER_Folder)\n","\n","  # Append the contents of the second list to the first\n","  unflattened_data = grouped_data_1 + grouped_data_2 #Combined data\n","\n","  PET_data = [item for group in grouped_data_1 for item in group]\n","\n","  LESCHNEIDER_data = [item for group in grouped_data_2 for item in group]\n","\n","  #Because the data is grouped according to doc_name, the unflattened_data is a list that contains lists. By unpacking we create a list containing not lists but the actual documents.\n","  combined_data = [item for group in unflattened_data for item in group] #Now input_data containts all the sentences.\n","\n","  if combined_data or PET_data or LESCHNEIDER_data:\n","    print(\"Data Loaded\")\n","\n","\n","\n","except FileNotFoundError as fnf:\n","  print(\"File was not found or incorrect file directory, please try to run cell again\")\n","\n"],"metadata":{"id":"RSejUqE27ow-","executionInfo":{"status":"ok","timestamp":1722434876495,"user_tz":-120,"elapsed":3070,"user":{"displayName":"Nam Le","userId":"03833879987749562665"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"06fa3e45-4535-4b8c-effe-6d6c0f7a9c2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Loaded\n"]}]},{"cell_type":"markdown","source":["#2. Pre-Processing of Input Data"],"metadata":{"id":"_IIgaCTa7biF"}},{"cell_type":"code","source":["#@title pre-processing functions\n","# Load GloVe model\n","def load_glove_model(glove_file_path):\n","    \"\"\"Load the GloVe model as a dictionary.\"\"\"\n","    embedding_dict = {}\n","    with open(glove_file_path, 'r', encoding='utf8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vector = list(map(float, values[1:]))\n","            embedding_dict[word] = vector\n","    return embedding_dict\n","\n","def word2features(sent, i, glove_model):\n","\n","    # Extract the current word and its POS tag\n","    word = sent[i]['token']\n","    postag = sent[i]['pos_tag']\n","\n","    # Initialize a dictionary to hold the features\n","    features = {\n","        'bias': 1.0,  # acts as an intercept term\n","        'word.lower()': word.lower(),  # Lowercase form of the word\n","        'word[-3:]': word[-3:],  # Last three characters of the word (suffix)\n","        'word[-2:]': word[-2:],  # Last two characters of the word (suffix)\n","        'word.isupper()': word.isupper(),  # Is the word in uppercase?\n","        'word.istitle()': word.istitle(),  # is the word title-cased?\n","        'word.isdigit()': word.isdigit(),  # is the word a digit?\n","        'postag': postag,  # Full POS tag of the word\n","        'postag[:2]': postag[:2],  # First two characters of the POS tag\n","    }\n","\n","    # Add GloVe embedding features for the current word\n","    if word in glove_model:\n","        glove_embedding = glove_model[word]\n","    else:\n","        glove_embedding = np.zeros(300)  # Use zero vector if word is not in GloVe model\n","\n","    # Add each dimension of the GloVe embedding as a feature\n","    for idx, val in enumerate(glove_embedding):\n","        features[f'glove_{idx}'] = val\n","\n","    # Add features for the previous word (if it exists)\n","    if i > 0:\n","        word1 = sent[i-1]['token']\n","        postag1 = sent[i-1]['pos_tag']\n","        features.update({\n","            '-1:word.lower()': word1.lower(),  # Lowercase form of the previous word\n","            '-1:word.istitle()': word1.istitle(),  # is the previous word title-cased?\n","            '-1:word.isupper()': word1.isupper(),  # is the previous word in uppercase?\n","            '-1:postag': postag1,  # Full POS tag of the previous word\n","            '-1:postag[:2]': postag1[:2],  # First two characters of the previous word's POS tag\n","        })\n","    else:\n","        features['BOS'] = True  # Indicate beginning of sentence\n","\n","    # Add features for the next word (if it exists)\n","    if i < len(sent) - 1:\n","        word1 = sent[i+1]['token']\n","        postag1 = sent[i+1]['pos_tag']\n","        features.update({\n","            '+1:word.lower()': word1.lower(),  # Lowercase form of the next word\n","            '+1:word.istitle()': word1.istitle(),  # Is the next word title-cased?\n","            '+1:word.isupper()': word1.isupper(),  # Is the next word in uppercase?\n","            '+1:postag': postag1,  # Full POS tag of the next word\n","            '+1:postag[:2]': postag1[:2],  # First two characters of the next word's POS tag\n","        })\n","    else:\n","        features['EOS'] = True  # Indicate end of sentence\n","\n","    return features\n","\n","# Extract features for CRF\n","def sent2features(sent):\n","    return [word2features(sent, i, glove_model) for i in range(len(sent))]\n","\n","# Modify preprocess_data function to include word2features\n","# Function to prepare data\n","def prepare_data(input_data):\n","    sentences = []\n","    labels = []\n","\n","    for entry in input_data:\n","        tokens = entry['tokens']\n","        ner_tags = entry['ner-tags']\n","        sentence = []\n","\n","        for token, ner_tag in zip(tokens, ner_tags):\n","            pos = pos_tag([token])[0][1]\n","            sentence.append({'token': token, 'pos_tag': pos})\n","\n","        sentences.append(sentence)\n","        labels.append(ner_tags)\n","\n","    return sentences, labels\n","\n","def get_sorted_labels_from_flat(all_y_test_flat):\n","\n","    pairs = []\n","    non_paired_labels = []\n","    unique_labels = set(all_y_test_flat)\n","\n","    for label in unique_labels:\n","        if label.startswith(\"B-\"):\n","            corresponding_i_label = label.replace(\"B-\", \"I-\")\n","            if corresponding_i_label in unique_labels:\n","                pairs.append((label, corresponding_i_label))\n","        elif label == 'O':\n","            non_paired_labels.append(label)\n","\n","    # Sort pairs alphabetically based on the B label\n","    pairs.sort(key=lambda pair: pair[0])\n","\n","    # Flatten the sorted pairs\n","    sorted_labels = [label for pair in pairs for label in pair]\n","    sorted_labels.extend(non_paired_labels)\n","\n","    return sorted_labels\n"],"metadata":{"id":"Wf2oppQxqIDq","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title pre-processing and splitting data\n","# Path to your GloVe file\n","glove_path = '/content/drive/MyDrive/THESIS/CODING/NAM_TESTING/TESTING DATA/RE_TRAINING_DATA/GloVe pre-trained/glove.6B.300d.txt'\n","\n","# Load the GloVe model\n","glove_model = load_glove_model(glove_path)\n","\n"],"metadata":{"id":"b2llXGjRdnf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title CrossValidation for CRF\n","def crossvalidation_CRF(sentences, labels, SEED):\n","  # Split the data into training and testing sets\n","\n","  kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n","  f1_scores = []\n","  all_y_test_flat = []\n","  all_y_pred_flat = []\n","\n","  for train_index, test_index in kf.split(sentences):\n","      X_train, X_test = [sentences[i] for i in train_index], [sentences[i] for i in test_index]\n","      y_train, y_test = [labels[i] for i in train_index], [labels[i] for i in test_index]\n","\n","      # Prepare feature sets\n","      X_train_feats = [sent2features(s) for s in X_train]\n","      X_test_feats = [sent2features(s) for s in X_test]\n","\n","      # Train the CRF model\n","      trainer = pycrfsuite.Trainer(verbose=False)\n","      for xseq, yseq in zip(X_train_feats, y_train):\n","          trainer.append(xseq, yseq)\n","\n","      # Set parameters for the CRF\n","      trainer.set_params({\n","          'c1': 1.0,   # coefficient for L1 penalty\n","          'c2': 1e-3,  # coefficient for L2 penalty\n","          'max_iterations': 75,  # stop earlier\n","          'feature.possible_transitions': True\n","      })\n","\n","      # Train the model\n","      trainer.train('crf.model')\n","\n","      # Load the trained model\n","      tagger = pycrfsuite.Tagger()\n","      tagger.open('crf.model')\n","\n","      # Predict on the test set\n","      y_pred = [tagger.tag(xseq) for xseq in X_test_feats]\n","\n","      # Flatten the predictions and true labels\n","      y_test_flat = [y for y_seq in y_test for y in y_seq]\n","      y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n","\n","      # Store results\n","      all_y_test_flat.extend(y_test_flat)\n","      all_y_pred_flat.extend(y_pred_flat)\n","\n","      # Calculate the micro F1 score for this fold and store it\n","      micro_f1 = f1_score(y_test_flat, y_pred_flat, average='micro')\n","      macro_f1 = f1_score(y_test_flat, y_pred_flat, average='macro')\n","      f1_scores.append(micro_f1)\n","\n","  # Calculate and print the overall micro F1 score\n","\n","  labels_flat = get_sorted_labels_from_flat([item for group in labels for item in group]) #we flatten it first before we put it in the sorting function\n","\n","  print('these are the labels_flat:',labels_flat)\n","  overall_micro_f1 = f1_score(all_y_test_flat, all_y_pred_flat, average='micro', labels=labels_flat)\n","  overall_macro_f1 = f1_score(all_y_test_flat, all_y_pred_flat, average='macro', labels=labels_flat)\n","  print(f\"Overall Micro F1 Score: {overall_micro_f1:.4f}\")\n","\n","  # Calculate overall precision, recall, and F1 score\n","  precision, recall, f1, _ = precision_recall_fscore_support(all_y_test_flat, all_y_pred_flat, average='micro', labels= labels_flat)\n","  print(f\"Overall Precision: {precision:.4f}\")\n","  print(f\"Overall Recall: {recall:.4f}\")\n","  print(f\"Overall F1 Score: {f1:.4f}\")\n","\n","\n","\n","  # Print the classification report for the overall results\n","  report = classification_report(all_y_test_flat, all_y_pred_flat, labels=labels_flat)\n","  print(report)\n","\n","  return overall_micro_f1, overall_macro_f1, f1_scores, report\n"],"metadata":{"id":"LzzCBD-WwAuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 1. Crossvalidation on PET Baseline\n","\n","# Process the input data\n","sentences_PET, labels_PET = prepare_data(PET_data)\n","\n","# Cross-validation\n","overall_micro_f1_PET, overall_macro_f1_PET, f1_scores_PET, report_PET = crossvalidation_CRF(sentences_PET, labels_PET, SEED)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKEH5K2CWJ6M","executionInfo":{"status":"ok","timestamp":1722435017828,"user_tz":-120,"elapsed":60579,"user":{"displayName":"Nam Le","userId":"03833879987749562665"}},"outputId":"c275d9d2-db3a-48e6-cec4-41afc2fcfb3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["these are the labels_flat: ['B-AND Gateway', 'I-AND Gateway', 'B-Activity', 'I-Activity', 'B-Activity Data', 'I-Activity Data', 'B-Actor', 'I-Actor', 'B-Condition Specification', 'I-Condition Specification', 'B-Further Specification', 'I-Further Specification', 'B-XOR Gateway', 'I-XOR Gateway', 'O']\n","Overall Micro F1 Score: 0.7237\n","Overall Precision: 0.7237\n","Overall Recall: 0.7237\n","Overall F1 Score: 0.7237\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["                           precision    recall  f1-score   support\n","\n","            B-AND Gateway       0.00      0.00      0.00         8\n","            I-AND Gateway       0.00      0.00      0.00         9\n","               B-Activity       0.81      0.76      0.78       502\n","               I-Activity       0.53      0.33      0.41        49\n","          B-Activity Data       0.76      0.71      0.73       459\n","          I-Activity Data       0.69      0.70      0.69      1158\n","                  B-Actor       0.81      0.78      0.80       449\n","                  I-Actor       0.77      0.77      0.77       598\n","B-Condition Specification       0.87      0.65      0.74        80\n","I-Condition Specification       0.74      0.59      0.65       403\n","  B-Further Specification       0.42      0.23      0.30        64\n","  I-Further Specification       0.27      0.19      0.22       268\n","            B-XOR Gateway       0.83      0.74      0.78       117\n","            I-XOR Gateway       0.80      0.39      0.52        31\n","                        O       0.73      0.80      0.76      3374\n","\n","                 accuracy                           0.72      7569\n","                macro avg       0.60      0.51      0.54      7569\n","             weighted avg       0.72      0.72      0.72      7569\n","\n"]}]},{"cell_type":"code","source":["#@title 2. Training on PET, Testing on LESCHNEIDER\n","\n","sentences_PET2, labels_PET2 = prepare_data(PET_data) # for clarity\n","sentences_LESCHNEIDER, labels_LESCHNEIDER = prepare_data(LESCHNEIDER_data)\n","\n","X_train, y_train = sentences_PET2, labels_PET2\n","X_test, y_test = sentences_LESCHNEIDER, labels_LESCHNEIDER\n","\n","# Prepare feature sets\n","X_train_feats = [sent2features(s) for s in X_train]\n","X_test_feats = [sent2features(s) for s in X_test]\n","\n","# Train the CRF model\n","trainer2 = pycrfsuite.Trainer(verbose=False)\n","for xseq, yseq in zip(X_train_feats, y_train):\n","    trainer2.append(xseq, yseq)\n","\n","# Set parameters for the CRF\n","trainer2.set_params({\n","    'c1': 1.0,   # coefficient for L1 penalty\n","    'c2': 1e-3,  # coefficient for L2 penalty\n","    'max_iterations': 50,  # stop earlier, we tested several\n","    'feature.possible_transitions': True\n","})\n","\n","# Train the model\n","trainer2.train('crf.model2')\n","\n","# Load the trained model\n","tagger = pycrfsuite.Tagger()\n","tagger.open('crf.model2')\n","\n","# Predict on the test set\n","y_pred = [tagger.tag(xseq) for xseq in X_test_feats]\n","\n","# Flatten the predictions and true labels\n","y_test_flat = [y for y_seq in y_test for y in y_seq]\n","y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n","\n","# Calculate the micro F1 score and store it\n","labels_flat = list(get_sorted_labels_from_flat(y_test_flat+y_pred_flat))\n","\n","micro_f1 = f1_score(y_test_flat, y_pred_flat, average='micro', labels= labels_flat)\n","macro_f1 = f1_score(y_test_flat, y_pred_flat, average='macro', labels= labels_flat)\n","#weighted_f1 = f1_score(y_test_flat, y_pred_flat, average='weighted', labels= labels_flat)\n","\n","print(f\"Micro F1 Score: {micro_f1:.4f}\")\n","print(f\"Macro F1 Score: {macro_f1:.4f}\")\n","#print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n","\n","report = classification_report(y_test_flat, y_pred_flat, labels= labels_flat)\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fl8GSggl40_E","executionInfo":{"status":"ok","timestamp":1721837238115,"user_tz":-120,"elapsed":16486,"user":{"displayName":"Nam Le","userId":"03833879987749562665"}},"outputId":"e3444c36-629d-438b-ea76-940c38a999db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Micro F1 Score: 0.6414\n","Macro F1 Score: 0.4921\n","                           precision    recall  f1-score   support\n","\n","            B-AND Gateway       0.00      0.00      0.00        32\n","            I-AND Gateway       0.00      0.00      0.00        77\n","               B-Activity       0.80      0.58      0.67       111\n","               I-Activity       1.00      0.11      0.20         9\n","          B-Activity Data       0.79      0.52      0.63       109\n","          I-Activity Data       0.71      0.56      0.63       184\n","                  B-Actor       0.95      0.63      0.76        93\n","                  I-Actor       0.97      0.66      0.79       101\n","B-Condition Specification       0.88      0.78      0.82        18\n","I-Condition Specification       0.95      0.86      0.90        65\n","  B-Further Specification       0.22      0.09      0.13        22\n","  I-Further Specification       0.28      0.24      0.26        68\n","            B-XOR Gateway       1.00      0.84      0.91        19\n","            I-XOR Gateway       0.00      0.00      0.00         4\n","                        O       0.55      0.90      0.68       510\n","\n","                 accuracy                           0.64      1422\n","                macro avg       0.61      0.45      0.49      1422\n","             weighted avg       0.63      0.64      0.61      1422\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["#@title 3. Crossvalidation on Combined Dataset\n","\n","sentences_combined, labels_combined = prepare_data(combined_data)\n","\n","# Cross-validation\n","overall_micro_f1_combined, overall_macro_f1_combined, f1_scores_combined, report_combined = crossvalidation_CRF(sentences_combined, labels_combined, SEED)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhP4j2E06zGP","executionInfo":{"status":"ok","timestamp":1721837319037,"user_tz":-120,"elapsed":80940,"user":{"displayName":"Nam Le","userId":"03833879987749562665"}},"outputId":"1d4ee2e6-29df-43b7-ce3a-cbe9cf98dc69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["these are the labels_flat: ['B-AND Gateway', 'I-AND Gateway', 'B-Activity', 'I-Activity', 'B-Activity Data', 'I-Activity Data', 'B-Actor', 'I-Actor', 'B-Condition Specification', 'I-Condition Specification', 'B-Further Specification', 'I-Further Specification', 'B-XOR Gateway', 'I-XOR Gateway', 'O']\n","Overall Micro F1 Score: 0.7283\n","                           precision    recall  f1-score   support\n","\n","            B-AND Gateway       0.50      0.15      0.23        40\n","            I-AND Gateway       0.07      0.06      0.07        86\n","               B-Activity       0.80      0.77      0.78       613\n","               I-Activity       0.67      0.38      0.48        58\n","          B-Activity Data       0.75      0.70      0.72       568\n","          I-Activity Data       0.70      0.71      0.70      1342\n","                  B-Actor       0.82      0.81      0.81       542\n","                  I-Actor       0.78      0.78      0.78       699\n","B-Condition Specification       0.88      0.69      0.78        98\n","I-Condition Specification       0.78      0.66      0.71       468\n","  B-Further Specification       0.49      0.27      0.35        86\n","  I-Further Specification       0.39      0.25      0.31       336\n","            B-XOR Gateway       0.81      0.77      0.79       136\n","            I-XOR Gateway       0.57      0.34      0.43        35\n","                        O       0.73      0.80      0.76      3884\n","\n","                 accuracy                           0.73      8991\n","                macro avg       0.65      0.54      0.58      8991\n","             weighted avg       0.72      0.73      0.72      8991\n","\n"]}]}]}